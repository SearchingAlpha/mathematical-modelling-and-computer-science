{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2.6: Numerical Methods Essentials - Exercises\n",
    "\n",
    "Welcome to the practical exercises for Section 2.6 of our Applied Mathematics for Complex Systems Modeling course. In this notebook, we'll apply the numerical methods we've learned to solve problems relevant to complex systems modeling.\n",
    "\n",
    "Before we begin, let's import the libraries we'll need throughout these exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "import scipy.integrate as integrate\n",
    "from scipy import linalg\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "# Set plotting parameters for better visualization\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Error Analysis, Root Finding, and Optimization (Solved)\n",
    "\n",
    "In this exercise, we'll explore numerical root-finding methods and analyze their convergence properties and errors. We'll compare different methods for finding the roots of a nonlinear equation that could represent an equilibrium point in a complex system.\n",
    "\n",
    "Consider the following nonlinear function which might represent a balance equation in a predator-prey system:\n",
    "\n",
    "$$f(x) = x^3 - 4x^2 + 5x - 2$$\n",
    "\n",
    "We want to find all roots of this equation (values of $x$ where $f(x) = 0$) using different numerical methods, and analyze their efficiency and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our function and its derivative\n",
    "def f(x):\n",
    "    return x**3 - 4*x**2 + 5*x - 2\n",
    "\n",
    "def df(x):\n",
    "    return 3*x**2 - 8*x + 5\n",
    "\n",
    "# Let's visualize the function to understand where the roots might be\n",
    "x_vals = np.linspace(0, 2, 1000)\n",
    "plt.figure()\n",
    "plt.plot(x_vals, f(x_vals))\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.grid(True)\n",
    "plt.title('Graph of f(x) = x³ - 4x² + 5x - 2')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.ylim(-3, 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Bisection Method Implementation\n",
    "\n",
    "Let's first implement the bisection method, which is robust but typically slower than other methods. We'll analyze its convergence rate and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection(f, a, b, tol=1e-6, max_iter=100):\n",
    "    \"\"\"Bisection method for finding roots of f(x) = 0.\n",
    "    \n",
    "    Parameters:\n",
    "    - f: Function to find roots for\n",
    "    - a, b: Initial interval bounds (f(a) and f(b) must have opposite signs)\n",
    "    - tol: Tolerance for convergence\n",
    "    - max_iter: Maximum number of iterations\n",
    "    \n",
    "    Returns:\n",
    "    - x_root: Approximate root\n",
    "    - iterations: Number of iterations performed\n",
    "    - errors: List of errors at each iteration\n",
    "    \"\"\"\n",
    "    # Check if f(a) and f(b) have opposite signs\n",
    "    if f(a) * f(b) >= 0:\n",
    "        raise ValueError(\"Function must have opposite signs at interval endpoints\")\n",
    "    \n",
    "    iterations = 0\n",
    "    errors = []\n",
    "    c_prev = a  # Previous midpoint (for error calculation)\n",
    "    \n",
    "    while (b - a) > tol and iterations < max_iter:\n",
    "        c = (a + b) / 2  # Midpoint\n",
    "        fc = f(c)\n",
    "        \n",
    "        # Calculate error (approximation since we don't know exact root)\n",
    "        if iterations > 0:\n",
    "            error = abs(c - c_prev)\n",
    "            errors.append(error)\n",
    "        \n",
    "        c_prev = c\n",
    "        \n",
    "        # Update interval\n",
    "        if fc == 0:\n",
    "            break  # Exact root found\n",
    "        elif f(a) * fc < 0:\n",
    "            b = c\n",
    "        else:\n",
    "            a = c\n",
    "            \n",
    "        iterations += 1\n",
    "    \n",
    "    return (a + b) / 2, iterations, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Newton-Raphson Method Implementation\n",
    "\n",
    "Now let's implement the Newton-Raphson method, which typically converges much faster than bisection but requires the derivative of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_raphson(f, df, x0, tol=1e-6, max_iter=100):\n",
    "    \"\"\"Newton-Raphson method for finding roots of f(x) = 0.\n",
    "    \n",
    "    Parameters:\n",
    "    - f: Function to find roots for\n",
    "    - df: Derivative of f\n",
    "    - x0: Initial guess\n",
    "    - tol: Tolerance for convergence\n",
    "    - max_iter: Maximum number of iterations\n",
    "    \n",
    "    Returns:\n",
    "    - x_root: Approximate root\n",
    "    - iterations: Number of iterations performed\n",
    "    - errors: List of errors at each iteration\n",
    "    \"\"\"\n",
    "    x = x0\n",
    "    iterations = 0\n",
    "    errors = []\n",
    "    \n",
    "    while iterations < max_iter:\n",
    "        fx = f(x)\n",
    "        dfx = df(x)\n",
    "        \n",
    "        if abs(dfx) < 1e-10:  # Avoid division by near-zero\n",
    "            raise ValueError(\"Derivative too close to zero\")\n",
    "        \n",
    "        x_new = x - fx / dfx\n",
    "        error = abs(x_new - x)\n",
    "        errors.append(error)\n",
    "        \n",
    "        if error < tol:\n",
    "            return x_new, iterations + 1, errors\n",
    "        \n",
    "        x = x_new\n",
    "        iterations += 1\n",
    "    \n",
    "    return x, iterations, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Comparing Methods\n",
    "\n",
    "Now let's compare the two methods and analyze their convergence and error properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the bisection method\n",
    "try:\n",
    "    bisection_root, bisection_iters, bisection_errors = bisection(f, 0.5, 1.5)\n",
    "    print(f\"Bisection Method:\")\n",
    "    print(f\"  Root: {bisection_root:.10f}\")\n",
    "    print(f\"  Iterations: {bisection_iters}\")\n",
    "    print(f\"  Function value at root: {f(bisection_root):.10e}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Bisection Method Error: {e}\")\n",
    "\n",
    "# Apply the Newton-Raphson method\n",
    "try:\n",
    "    newton_root, newton_iters, newton_errors = newton_raphson(f, df, 1.0)\n",
    "    print(f\"\\nNewton-Raphson Method:\")\n",
    "    print(f\"  Root: {newton_root:.10f}\")\n",
    "    print(f\"  Iterations: {newton_iters}\")\n",
    "    print(f\"  Function value at root: {f(newton_root):.10e}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Newton-Raphson Method Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Error Analysis and Convergence Visualization\n",
    "\n",
    "Let's visualize the error convergence for both methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot error vs. iteration\n",
    "plt.subplot(1, 2, 1)\n",
    "if 'bisection_errors' in locals() and len(bisection_errors) > 0:\n",
    "    plt.plot(range(1, len(bisection_errors) + 1), bisection_errors, 'o-', label='Bisection')\n",
    "if 'newton_errors' in locals() and len(newton_errors) > 0:\n",
    "    plt.plot(range(1, len(newton_errors) + 1), newton_errors, 's-', label='Newton-Raphson')\n",
    "plt.yscale('log')  # Logarithmic scale to better see convergence rate\n",
    "plt.grid(True)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Error (log scale)')\n",
    "plt.title('Error vs. Iteration')\n",
    "plt.legend()\n",
    "\n",
    "# Plot error ratio to see convergence order\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "# For Bisection - should be approximately linear (order 1)\n",
    "if 'bisection_errors' in locals() and len(bisection_errors) > 1:\n",
    "    bisection_ratios = [bisection_errors[i] / bisection_errors[i-1] if bisection_errors[i-1] != 0 else np.nan \n",
    "                        for i in range(1, len(bisection_errors))]\n",
    "    plt.plot(range(2, len(bisection_errors) + 1), bisection_ratios, 'o-', label='Bisection')\n",
    "\n",
    "# For Newton - should be approximately quadratic (order 2)\n",
    "if 'newton_errors' in locals() and len(newton_errors) > 1:\n",
    "    newton_ratios = [newton_errors[i] / (newton_errors[i-1]**2) if newton_errors[i-1] != 0 else np.nan \n",
    "                     for i in range(1, len(newton_errors))]\n",
    "    plt.plot(range(2, len(newton_errors) + 1), newton_ratios, 's-', label='Newton-Raphson')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Error Ratio')\n",
    "plt.title('Convergence Order Analysis')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Finding All Roots using SciPy\n",
    "\n",
    "Now let's use SciPy's optimization tools to find all roots of our polynomial. For polynomials, we can directly find all roots using `np.roots`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all roots using numpy's polynomial root finder\n",
    "polynomial_coeffs = [1, -4, 5, -2]  # coefficients of x^3 - 4x^2 + 5x - 2\n",
    "all_roots = np.roots(polynomial_coeffs)\n",
    "\n",
    "print(\"All roots of the polynomial:\")\n",
    "for i, root in enumerate(all_roots):\n",
    "    if abs(root.imag) < 1e-10:  # Real root\n",
    "        root = root.real\n",
    "        print(f\"Root {i+1}: {root:.10f} (real)\")\n",
    "        print(f\"   f(root) = {f(root):.10e}\")\n",
    "    else:  # Complex root\n",
    "        print(f\"Root {i+1}: {root} (complex)\")\n",
    "        print(f\"   f(root) = {f(complex(root)):.10e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Key Observations and Analysis\n",
    "\n",
    "From our numerical experiments, we can observe and explain several important aspects of numerical root-finding:\n",
    "\n",
    "1. **Convergence Rate**:\n",
    "   - The bisection method shows linear convergence (error reduces by approximately a constant factor in each iteration).\n",
    "   - The Newton-Raphson method demonstrates quadratic convergence (error is approximately squared in each iteration), making it much faster near the solution.\n",
    "\n",
    "2. **Error Analysis**:\n",
    "   - The Newton-Raphson method typically requires fewer iterations to reach the same tolerance.\n",
    "   - However, the bisection method is more robust and guaranteed to converge if the initial interval contains a root.\n",
    "\n",
    "3. **Method Selection Criteria**:\n",
    "   - Newton-Raphson requires the derivative of the function, which may not always be available or easy to calculate.\n",
    "   - Newton-Raphson needs a good initial guess, while bisection needs an interval bracketing the root.\n",
    "   - For polynomials specifically, specialized methods (like `np.roots`) can find all roots simultaneously.\n",
    "\n",
    "4. **Implications for Complex Systems**:\n",
    "   - In complex systems modeling, finding equilibrium points often requires solving nonlinear equations.\n",
    "   - The choice of numerical method depends on problem characteristics, available information, and computational constraints.\n",
    "   - Understanding convergence properties helps in developing efficient and reliable simulation algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Numerical Solution of Differential Equations (Unsolved)\n",
    "\n",
    "In this exercise, you'll explore numerical methods for solving differential equations, which are fundamental to modeling dynamic complex systems. You'll compare different integration methods for accuracy, stability, and computational efficiency.\n",
    "\n",
    "Consider the Lotka-Volterra predator-prey model, a classic example of a nonlinear dynamical system:\n",
    "\n",
    "$$\\frac{dx}{dt} = \\alpha x - \\beta xy$$\n",
    "$$\\frac{dy}{dt} = \\delta xy - \\gamma y$$\n",
    "\n",
    "where:\n",
    "- $x$ is the prey population\n",
    "- $y$ is the predator population\n",
    "- $\\alpha, \\beta, \\gamma, \\delta$ are positive parameters\n",
    "\n",
    "For this exercise, we'll use the following parameter values:\n",
    "- $\\alpha = 1.1$ (prey growth rate)\n",
    "- $\\beta = 0.4$ (prey death rate due to predation)\n",
    "- $\\gamma = 0.4$ (predator death rate)\n",
    "- $\\delta = 0.1$ (predator growth rate from consuming prey)\n",
    "\n",
    "Initial conditions: $x(0) = 10, y(0) = 5$\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "1. Implement the forward Euler method to solve this system over the time interval $[0, 50]$ with different step sizes.\n",
    "2. Implement a higher-order method (e.g., 4th-order Runge-Kutta) for the same problem.\n",
    "3. Compare the methods in terms of:\n",
    "   - Numerical stability\n",
    "   - Accuracy\n",
    "   - Computational efficiency\n",
    "4. Analyze how the choice of step size affects the solution.\n",
    "5. Create phase plane plots (x vs. y) to visualize the system dynamics.\n",
    "6. Calculate and analyze the conservation law for the Lotka-Volterra model.\n",
    "\n",
    "To help you get started, here's a template for implementing the differential equations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Lotka-Volterra equations\n",
    "def lotka_volterra(t, state, params):\n",
    "    \"\"\"Lotka-Volterra predator-prey model.\n",
    "    \n",
    "    Parameters:\n",
    "    - t: Time (not used in autonomous system but required for solvers)\n",
    "    - state: Current state [x, y] (prey and predator populations)\n",
    "    - params: Model parameters [alpha, beta, gamma, delta]\n",
    "    \n",
    "    Returns:\n",
    "    - derivatives: [dx/dt, dy/dt]\n",
    "    \"\"\"\n",
    "    x, y = state\n",
    "    alpha, beta, gamma, delta = params\n",
    "    \n",
    "    dxdt = alpha * x - beta * x * y\n",
    "    dydt = delta * x * y - gamma * y\n",
    "    \n",
    "    return np.array([dxdt, dydt])\n",
    "\n",
    "# Parameters and initial conditions\n",
    "alpha, beta, gamma, delta = 1.1, 0.4, 0.4, 0.1\n",
    "params = [alpha, beta, gamma, delta]\n",
    "initial_state = np.array([10.0, 5.0])\n",
    "t_span = (0, 50)\n",
    "\n",
    "# TODO: Implement forward Euler method\n",
    "\n",
    "# TODO: Implement 4th-order Runge-Kutta method\n",
    "\n",
    "# TODO: Compare solutions and analyze results\n",
    "\n",
    "# TODO: Create phase plane plots\n",
    "\n",
    "# TODO: Analyze conservation law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints for Exercise 2:\n",
    "\n",
    "1. **Forward Euler Method**:\n",
    "   - The update rule is: $y_{n+1} = y_n + h \\cdot f(t_n, y_n)$\n",
    "   - Be careful with the step size selection as Euler's method can become unstable.\n",
    "\n",
    "2. **4th-order Runge-Kutta Method**:\n",
    "   - This method uses a weighted average of function evaluations at different points.\n",
    "   - The formula involves calculating $k_1, k_2, k_3, k_4$ and using them to update the state.\n",
    "\n",
    "3. **Stability Analysis**:\n",
    "   - Look for signs of numerical instability: growing oscillations, unbounded solutions, etc.\n",
    "   - Try different step sizes to identify stability thresholds.\n",
    "\n",
    "4. **Conservation Law**:\n",
    "   - The Lotka-Volterra system has a conserved quantity (not constant but related to the energy).\n",
    "   - Try to derive and verify this conservation law numerically.\n",
    "\n",
    "5. **Using SciPy**:\n",
    "   - After implementing your own methods, you can use `scipy.integrate.solve_ivp` as a reference solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Exploration\n",
    "\n",
    "After completing these exercises, consider these extensions:\n",
    "\n",
    "1. Explore adaptive step size methods for differential equations.\n",
    "2. Implement implicit methods for stiff systems.\n",
    "3. Apply these numerical techniques to a real-world complex system from your field of interest.\n",
    "4. Analyze the numerical stability of different methods for various types of differential equations.\n",
    "5. Investigate how error propagates in numerical solutions over long time scales, which is critical for complex systems where small errors might significantly impact long-term behavior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}